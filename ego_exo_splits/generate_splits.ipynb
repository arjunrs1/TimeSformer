{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: This notebook is very similar to generate_demonstrator_proficiency_splits.ipynb in data_processing/ego_exo. Remove this script before releasing codebase.\n",
    "#NOTE: First, compare against that notebook and make any necessary changes to that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_exo_data_dir = \"/vision/asomaya1/ego_exo/data\" #replace with directory to data\n",
    "\n",
    "train_file = \"demonstrator_arxiv24_train.json\"\n",
    "val_file = \"demonstrator_arxiv24_val.json\"\n",
    "test_file = \"demonstrator_arxiv24_test.json\"\n",
    "is_v2 = True if \"24\" in train_file else False\n",
    "v2_downsampled_rel_path = \"downscaled/448\"\n",
    "\n",
    "train_path = os.path.join(ego_exo_data_dir, train_file)\n",
    "val_path = os.path.join(ego_exo_data_dir, val_file)\n",
    "test_path = os.path.join(ego_exo_data_dir, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(val_path, \"rb\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "with open(test_path, \"rb\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create demonstrator proficiency annotation encoding:\n",
    "train_labels = set([elem['proficiency_score'] for elem in train_data])\n",
    "val_labels = set([elem['proficiency_score'] for elem in val_data])\n",
    "test_labels = set([elem['proficiency_score'] for elem in test_data])\n",
    "demonstrator_proficiency_labels = train_labels.union(val_labels).union(test_labels)\n",
    "label_map = {'Novice': 0, 'Early Expert': 3, 'Intermediate Expert': 2, 'Late Expert': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ego + exo view names\n",
    "camera_views = ['ego', 'exo1', 'exo2', 'exo3', 'exo4']\n",
    "\n",
    "resolution = \"takes_448pFull\"\n",
    "if is_v2:\n",
    "    resolution += \"_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train split\n",
    "train_data_paths = {}\n",
    "all_exo_train_data_paths = []\n",
    "for view in camera_views:\n",
    "    train_data_paths[view] = []\n",
    "for elem in train_data:\n",
    "    label = label_map[elem['proficiency_score']]\n",
    "    video_paths = elem['video_paths']\n",
    "    for view in camera_views:\n",
    "        path = video_paths[view].replace(\"takes\", resolution)\n",
    "        if is_v2: #fixes formatting issue in arxiv24 files\n",
    "            path = path.split(\"/\", maxsplit=1)[1]\n",
    "            parts = path.split(\"/\")\n",
    "            directory_to_find = \"frame_aligned_videos\"\n",
    "            index = parts.index(directory_to_find) + 1\n",
    "            parts.insert(index, v2_downsampled_rel_path)\n",
    "            path = \"/\".join(parts)\n",
    "        train_data_paths[view].append((path, label))\n",
    "        if view != 'ego':\n",
    "            all_exo_train_data_paths.append((path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create val split\n",
    "val_data_paths = {}\n",
    "all_exo_val_data_paths = []\n",
    "for view in camera_views:\n",
    "    val_data_paths[view] = []\n",
    "for elem in val_data:\n",
    "    label = label_map[elem['proficiency_score']]\n",
    "    video_paths = elem['video_paths']\n",
    "    for view in camera_views:\n",
    "        path = video_paths[view].replace(\"takes\", resolution)\n",
    "        if is_v2: #fixes formatting issue in arxiv24 files\n",
    "            path = path.split(\"/\", maxsplit=1)[1]\n",
    "            parts = path.split(\"/\")\n",
    "            directory_to_find = \"frame_aligned_videos\"\n",
    "            index = parts.index(directory_to_find) + 1\n",
    "            parts.insert(index, v2_downsampled_rel_path)\n",
    "            path = \"/\".join(parts)\n",
    "        val_data_paths[view].append((path, label))\n",
    "        if view != 'ego':\n",
    "            all_exo_val_data_paths.append((path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test split\n",
    "test_data_paths = {}\n",
    "all_exo_test_data_paths = []\n",
    "for view in camera_views:\n",
    "    test_data_paths[view] = []\n",
    "for elem in test_data:\n",
    "    label = label_map[elem['proficiency_score']]\n",
    "    video_paths = elem['video_paths']\n",
    "    for view in camera_views:\n",
    "        path = video_paths[view].replace(\"takes\", resolution)\n",
    "        if is_v2: #fixes formatting issue in arxiv24 files\n",
    "            path = path.split(\"/\", maxsplit=1)[1]\n",
    "            parts = path.split(\"/\")\n",
    "            directory_to_find = \"frame_aligned_videos\"\n",
    "            index = parts.index(directory_to_find) + 1\n",
    "            parts.insert(index, v2_downsampled_rel_path)\n",
    "            path = \"/\".join(parts)\n",
    "        test_data_paths[view].append((path, label))\n",
    "        if view != 'ego':\n",
    "            all_exo_test_data_paths.append((path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits to csv\n",
    "for view in camera_views:\n",
    "    view_path = os.path.join(resolution.split(\"_\", maxsplit=1)[-1], view)\n",
    "    if not os.path.exists(view_path):\n",
    "        os.makedirs(view_path)\n",
    "\n",
    "for view in camera_views:\n",
    "    view_path = os.path.join(resolution.split(\"_\", maxsplit=1)[-1], view)\n",
    "    with open(os.path.join(view_path, \"train.csv\"), \"w\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        for item in train_data_paths[view]:\n",
    "            csv_writer.writerow([f\"{item[0]} {item[1]}\"])\n",
    "\n",
    "for view in camera_views:\n",
    "    view_path = os.path.join(resolution.split(\"_\", maxsplit=1)[-1], view)\n",
    "    with open(os.path.join(view_path, \"val.csv\"), \"w\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        for item in val_data_paths[view]:\n",
    "            csv_writer.writerow([f\"{item[0]} {item[1]}\"])\n",
    "\n",
    "for view in camera_views:\n",
    "    view_path = os.path.join(resolution.split(\"_\", maxsplit=1)[-1], view)\n",
    "    with open(os.path.join(view_path, \"test.csv\"), \"w\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        for item in test_data_paths[view]:\n",
    "            csv_writer.writerow([f\"{item[0]} {item[1]}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(resolution.split(\"_\", maxsplit=1)[-1], \"exo_all\")):\n",
    "        os.makedirs(os.path.join(resolution.split(\"_\", maxsplit=1)[-1], \"exo_all\"))\n",
    "\n",
    "#save all_exo splits to csv\n",
    "with open(os.path.join(resolution.split(\"_\", maxsplit=1)[-1], \"exo_all\", \"train.csv\"), \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for item in all_exo_train_data_paths:\n",
    "        csv_writer.writerow([f\"{item[0]} {item[1]}\"])\n",
    "\n",
    "with open(os.path.join(resolution.split(\"_\", maxsplit=1)[-1], \"exo_all\", \"val.csv\"), \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for item in all_exo_val_data_paths:\n",
    "        csv_writer.writerow([f\"{item[0]} {item[1]}\"])\n",
    "\n",
    "with open(os.path.join(resolution.split(\"_\", maxsplit=1)[-1], \"exo_all\", \"test.csv\"), \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for item in all_exo_test_data_paths:\n",
    "        csv_writer.writerow([f\"{item[0]} {item[1]}\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
